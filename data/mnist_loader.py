# -*- coding: utf-8 -*-
"""mnist_loader.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1siZDBo1zkBnWf_pHT9gU4Wyo-6EV8g59
"""

# import basic libraries
import os
import torch
from torch.utils.data import DataLoader
from torchvision import transforms
import medmnist
from medmnist import INFO

def get_data(dataset_name: str = "PathMNIST",
                        im_size: int = 28,
                        batch_size: int = 64,
                        data_dir: str = "./data/dataset"):
  """
  Load data from medmnist dataset.
  Input: DataSet name must be a string with the exact same name of the data set (eg. "PathMNIST", "DermaMNIST").
         im_size: either 28 for 28x28 mnist images or 224 for 224x224 (required for pretrained model) mnist images 
         batch_size: size of the batch that is going to be used for training.
         data_dir: the name of the directory you want to download and save the dataset.

  Output: train_loader, val_loader, test_loader. The training, validation and test data loaders.
  """
  DatasetClass = getattr(medmnist, dataset_name) # returns the attribute of the medmnist module (eg. medmnist.PathMNIST)

  # get the mean and std to later normalize it
  flag = dataset_name.lower()


  # define the transform to convert the data to tensor format and normalize it
  transform = transforms.Compose([transforms.ToTensor(),
                                  transforms.Normalize(mean=[.5], std=[.5])
                                  ])
  # ensure root folder exists
  root_dir = os.path.join(data_dir, flag)
  os.makedirs(root_dir, exist_ok=True)

  # separate in training, validation and test
  train_ds = DatasetClass(root=root_dir, split="train", transform=transform, size = im_size, download=True)
  val_ds = DatasetClass(root=root_dir, split="val",   transform=transform, size = im_size, download=True)
  test_ds = DatasetClass(root=root_dir, split="test",  transform=transform, size = im_size, download=True)

  # put each one of them in the pytorch DataLoader
  train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)
  val_loader = DataLoader(val_ds,   batch_size=batch_size, shuffle=False)
  test_loader = DataLoader(test_ds,  batch_size=batch_size, shuffle=False)

  return train_loader, val_loader, test_loader


if __name__ ==  "__main__":
    # example usage
    train_set, val_set, test_set = get_data("PathMNIST", im_size=224)

    # getting info about what's in the train_set
    ds = train_set.dataset

    print("dataset type:", type(ds))
    print("dataset size:", len(ds))

    # index into ds itself
    x0, y0 = ds[0]   # first example from the raw dataset
    print("X data shape:", x0.shape)
    print("y data shape:", y0.shape)
